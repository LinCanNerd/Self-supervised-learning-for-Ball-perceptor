{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.AppleModel import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "image_dir = \"acfr-multifruit-2016/acfr-fruit-dataset/apples/images\"\n",
    "annotation_dir = \"acfr-multifruit-2016/acfr-fruit-dataset/apples/annotations\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((202,308)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = AppleDataset(image_dir, annotation_dir, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4,collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AppleDetector(num_classes=2)\n",
    "\n",
    "# Move model to the desired device (GPU/CPU)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Define the optimizer (e.g., Adam)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     optimizer.step()\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Keep track of the total loss for this batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     total_loss += \u001b[43mlosses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Average loss for the epoch\u001b[39;00m\n\u001b[32m     29\u001b[39m avg_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, annotations in train_loader:\n",
    "\n",
    "        images = list(img.to(device) for img in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        \n",
    "        # Total loss is the sum of all the losses in the dictionary\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # Backward pass\n",
    "        losses.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Keep track of the total loss for this batch\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Step the learning rate scheduler (optional)\n",
    "    if lr_scheduler:\n",
    "        lr_scheduler.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
